{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Rover Iteration 2: Software","title":"Software"},{"location":"#rover-iteration-2-software","text":"","title":"Rover Iteration 2: Software"},{"location":"features/","text":"Rover Iteration 2 Features Controller Covers everything outside of autonomous control. Canbus-layer Create an abstract Layer to improve canbus messaging between systems and modularity as well as documentation as code for handover purposes. Command-gui Improved command GUI with integrated sensory information, arm and drive control capabilities and autonomous controls. Debug and console values should also be sent here. Pid-interface Help with the construction of a PID interface that all motors can use, help with integration to interface with arm and drive motor controllers. Autonomous Odometry-localisation-and-navigation Fuse all Odometry information and perform ekf localisation and navigation. Localise against a coordinate grid. Landmark-localisation Perform AR Tag Detection on Realsense to determine distance. Localise against a coordinate grid, account for error in Odometry information. Obstacle-detection-and-avoidance Use LIDAR and Depth Camera to detect and avoid obstacles Slope-detection Use Odom and Realsense to determine slopes the rover can attempt to climb. Jetson and Code Cleanliness Build-and-deploy-objects On Git push, code will be tested and deployed to the jetson via jenkins jobs. This would allow us to minify and optimise builds as well as keep hard drive size minimal. Would require: AWS Cloud services and JFrog Artifactory.","title":"Features"},{"location":"features/#rover-iteration-2-features","text":"","title":"Rover Iteration 2 Features"},{"location":"features/#controller","text":"Covers everything outside of autonomous control. Canbus-layer Create an abstract Layer to improve canbus messaging between systems and modularity as well as documentation as code for handover purposes. Command-gui Improved command GUI with integrated sensory information, arm and drive control capabilities and autonomous controls. Debug and console values should also be sent here. Pid-interface Help with the construction of a PID interface that all motors can use, help with integration to interface with arm and drive motor controllers.","title":"Controller"},{"location":"features/#autonomous","text":"Odometry-localisation-and-navigation Fuse all Odometry information and perform ekf localisation and navigation. Localise against a coordinate grid. Landmark-localisation Perform AR Tag Detection on Realsense to determine distance. Localise against a coordinate grid, account for error in Odometry information. Obstacle-detection-and-avoidance Use LIDAR and Depth Camera to detect and avoid obstacles Slope-detection Use Odom and Realsense to determine slopes the rover can attempt to climb.","title":"Autonomous"},{"location":"features/#jetson-and-code-cleanliness","text":"Build-and-deploy-objects On Git push, code will be tested and deployed to the jetson via jenkins jobs. This would allow us to minify and optimise builds as well as keep hard drive size minimal. Would require: AWS Cloud services and JFrog Artifactory.","title":"Jetson and Code Cleanliness"}]}